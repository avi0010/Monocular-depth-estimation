{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-10T07:06:18.790327Z","iopub.execute_input":"2023-04-10T07:06:18.791147Z","iopub.status.idle":"2023-04-10T07:06:56.131104Z","shell.execute_reply.started":"2023-04-10T07:06:18.791069Z","shell.execute_reply":"2023-04-10T07:06:56.130054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models.resnet import resnet18 as _resnet34\nimport torch\nimport torch.nn as nn\nimport torchvision as T","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:06:56.133233Z","iopub.execute_input":"2023-04-10T07:06:56.134002Z","iopub.status.idle":"2023-04-10T07:06:58.697318Z","shell.execute_reply.started":"2023-04-10T07:06:56.133963Z","shell.execute_reply":"2023-04-10T07:06:58.695616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _make_resnet_backbone(resnet):\n    pretrained = nn.Module()\n    pretrained.conv0_0 = nn.Sequential(\n    resnet.conv1, resnet.bn1, resnet.relu, resnet.layer1)\n    pretrained.conv1_0 = resnet.layer2\n    pretrained.conv2_0 = resnet.layer3\n    pretrained.conv3_0 = resnet.layer4\n    return pretrained\n\ndef resnet34(pretrained=True, **kwargs):\n    model = _resnet34(pretrained=pretrained, **kwargs)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:06:58.702550Z","iopub.execute_input":"2023-04-10T07:06:58.703318Z","iopub.status.idle":"2023-04-10T07:06:58.713966Z","shell.execute_reply.started":"2023-04-10T07:06:58.703268Z","shell.execute_reply":"2023-04-10T07:06:58.712631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Upscale_Block(nn.Module):\n    def __init__(self, input_channel, out):\n        super().__init__()\n        self.cv1 = nn.Conv2d(input_channel, out, 3, stride=(1, 1), padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out)\n        self.cv2 = nn.Conv2d(out, out, 3, stride=(1, 1), padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out)\n        self.relu = nn.ReLU(inplace=True)\n        self.cv3 = nn.Conv2d(out, out, 3, stride=(1, 1), padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out)\n        self.cv4 = nn.Conv2d(out, out, 3, stride=(1, 1), padding=1, bias=False)\n        self.bn4 = nn.BatchNorm2d(out)\n\n    def forward(self, x):\n        out = self.cv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.cv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.cv3(out)\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.cv4(out)\n        out = self.bn4(out)\n        out = self.relu(out)\n\n        return out\n\nclass Interpolate(nn.Module):\n    def __init__(self, scale_factor, mode, align_corners=False):\n        super(Interpolate, self).__init__()\n        self.interp = nn.functional.interpolate\n        self.scale_factor = scale_factor\n        self.mode = mode\n        self.align_corners = align_corners\n\n    def forward(self, x):\n        x = self.interp(\n            x,\n            scale_factor=self.scale_factor,\n            mode=self.mode,\n            align_corners=self.align_corners,\n        )\n        return x\n    \nclass VGGBlock(nn.Module):\n    def __init__(self, in_channels, middle_channels, out_channels):\n        super().__init__()\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(middle_channels)\n        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:06:58.717874Z","iopub.execute_input":"2023-04-10T07:06:58.718714Z","iopub.status.idle":"2023-04-10T07:06:58.751880Z","shell.execute_reply.started":"2023-04-10T07:06:58.718673Z","shell.execute_reply":"2023-04-10T07:06:58.750472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DV3(nn.Module):\n    def __init__(self, input_channels=3, **kwargs):\n        super().__init__()\n        nb_filter = [64, 128, 256, 512, 1024]\n        model = resnet34()\n        self.encoder = _make_resnet_backbone(model)\n        #self.conv0_0 = nn.Conv2d(3, 64, 3, padding=1)\n        self.conv4_0 = nn.Sequential(\n            nn.ReLU(),\n            nn.Conv2d(512, 1024, 3, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.MaxPool2d(2, 2),\n        )\n        self.final = nn.Conv2d(nb_filter[0], 1, kernel_size=1)\n        self.up = Interpolate(scale_factor=2, mode=\"bilinear\", align_corners=True)\n        self.conv0_1 = VGGBlock(nb_filter[0] + nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_1 = VGGBlock(nb_filter[1] + nb_filter[2], nb_filter[1], nb_filter[1])\n        self.conv2_1 = VGGBlock(nb_filter[2] + nb_filter[3], nb_filter[2], nb_filter[2])\n        self.conv3_1 = Upscale_Block(nb_filter[3] + nb_filter[4], nb_filter[3])\n        self.conv0_2 = VGGBlock(nb_filter[0] * 2 + nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_2 = VGGBlock(nb_filter[1] * 2 + nb_filter[2], nb_filter[1], nb_filter[1])\n        self.conv2_2 = Upscale_Block(nb_filter[2] * 2 + nb_filter[3], nb_filter[2])\n        self.conv0_3 = VGGBlock(nb_filter[0] * 3 + nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_3 = Upscale_Block(nb_filter[1] * 3 + nb_filter[2], nb_filter[1])\n        self.conv0_4 = Upscale_Block(nb_filter[0] * 4 + nb_filter[1], nb_filter[0])\n\n    def forward(self, input):\n        # input_layer = self.conv0_0(input)\n        x0_0 = self.encoder.conv0_0(input)\n        x1_0 = self.encoder.conv1_0(x0_0)\n        x2_0 = self.encoder.conv2_0(x1_0)\n        x3_0 = self.encoder.conv3_0(x2_0)\n        x4_0 = self.conv4_0(x3_0)\n        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n        out = self.up(x0_4)\n        out = self.final(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:06:58.753982Z","iopub.execute_input":"2023-04-10T07:06:58.754967Z","iopub.status.idle":"2023-04-10T07:06:58.780099Z","shell.execute_reply.started":"2023-04-10T07:06:58.754927Z","shell.execute_reply":"2023-04-10T07:06:58.778597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#weights = DV3()\nweights = torch.load(\"/kaggle/input/model4-weights3/model_4(17)_0.000840797853375859.pth\")\n#lst = [\"encoder\"]\nnetwork = weights.cuda()\nfor name,param in network.named_parameters():\n    param.requires_grad = True\n#for name,param in weights.named_parameters():\n    #print(name)\n    #for i in lst:\n        #if i in name:\n            #param.requires_grad = False\n    #print(name, '---->' ,param.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:06:58.785415Z","iopub.execute_input":"2023-04-10T07:06:58.786271Z","iopub.status.idle":"2023-04-10T07:07:02.907835Z","shell.execute_reply.started":"2023-04-10T07:06:58.786194Z","shell.execute_reply":"2023-04-10T07:07:02.906776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport os, os.path\nimport cv2\nimport imageio\nimport torch.nn as nn\nimport glob\nimport time\nimport numpy as np\nimport scipy.ndimage\nimport math\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n%matplotlib inline\n\nimport torch\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.io import read_image","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:02.909441Z","iopub.execute_input":"2023-04-10T07:07:02.909805Z","iopub.status.idle":"2023-04-10T07:07:03.145909Z","shell.execute_reply.started":"2023-04-10T07:07:02.909766Z","shell.execute_reply":"2023-04-10T07:07:03.144886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp = pd.read_csv('../input/nyu-depth-v2/nyu_data/data/nyu2_train.csv', names=['image', 'label'])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.147511Z","iopub.execute_input":"2023-04-10T07:07:03.147910Z","iopub.status.idle":"2023-04-10T07:07:03.282160Z","shell.execute_reply.started":"2023-04-10T07:07:03.147867Z","shell.execute_reply":"2023-04-10T07:07:03.281075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp = df_temp.sample(frac = 1 , random_state = 79)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.283917Z","iopub.execute_input":"2023-04-10T07:07:03.284313Z","iopub.status.idle":"2023-04-10T07:07:03.299166Z","shell.execute_reply.started":"2023-04-10T07:07:03.284263Z","shell.execute_reply":"2023-04-10T07:07:03.298235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_temp[:42000]\ndf_val = df_temp[42000:]","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.303156Z","iopub.execute_input":"2023-04-10T07:07:03.303685Z","iopub.status.idle":"2023-04-10T07:07:03.308711Z","shell.execute_reply.started":"2023-04-10T07:07:03.303655Z","shell.execute_reply":"2023-04-10T07:07:03.307452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.reset_index()\ndf_train.drop(['index'] , axis = 1 ,inplace = True)\n\ndf_val = df_val.reset_index()\ndf_val.drop(['index'] , axis = 1 ,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.310830Z","iopub.execute_input":"2023-04-10T07:07:03.311344Z","iopub.status.idle":"2023-04-10T07:07:03.328143Z","shell.execute_reply.started":"2023-04-10T07:07:03.311269Z","shell.execute_reply":"2023-04-10T07:07:03.327082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, root_dir, data_dir, transform=None, target_transform=None):\n        '''\n        The __init__ function is run once when instantiating the Dataset object\n        '''\n#         self.img_labels = pd.read_csv(annotations_file)\n#         self.img_dir = img_dir\n        self.root_dir = root_dir\n        self.data_dir = data_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        '''\n        The __len__ function returns the number of samples in dataset\n        '''\n        return len(self.data_dir)\n\n    def __getitem__(self, idx):\n        '''\n        The __getitem__ function loads and returns a sample from the dataset at the given index idx\n        '''\n        img_path = os.path.join(self.root_dir, self.data_dir['image'][idx])\n        image = Image.open(img_path)\n        \n\n        label_path = os.path.join(self.root_dir, self.data_dir['label'][idx])\n        label = Image.open(label_path)\n        \n        seed = np.random.randint(2147483647) # make a seed with numpy generator \n        \n        if self.transform is not None:\n            random.seed(seed) # apply this seed to img tranfsorms\n            torch.manual_seed(seed) # needed for torchvision 0.7\n            image = self.transform(image)\n        if self.target_transform is not None:\n            random.seed(seed) # apply this seed to target tranfsorms\n            torch.manual_seed(seed) # needed for  torchvision 0.7\n            label = self.target_transform(label)\n          \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.329994Z","iopub.execute_input":"2023-04-10T07:07:03.330737Z","iopub.status.idle":"2023-04-10T07:07:03.340741Z","shell.execute_reply.started":"2023-04-10T07:07:03.330698Z","shell.execute_reply":"2023-04-10T07:07:03.339684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '../input/nyu-depth-v2/nyu_data'\ntrain_dir = '/kaggle/working/train.csv'\nval_dir = '/kaggle/working/val.csv'\ntransform = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomApply(transforms=[transforms.ColorJitter(brightness=.3, hue=.1)], p=0.25),\n            transforms.RandomApply(transforms=[transforms.GaussianBlur(kernel_size=(11, 11), sigma=(0.1, 5))], p=0.5),\n            transforms.Resize((512, 512)), # resize, the smaller edge will be matched.\n            transforms.ToTensor(), # convert a PIL image or ndarray to tensor. \n])\n\nval_transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.Resize((512, 512)), # resize, the smaller edge will be matched.\n            transforms.ToTensor(), # convert a PIL image or ndarray to tensor. \n])\n\ntarget_transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.Resize((512, 512)), # resize, the smaller edge will be ma\n            transforms.ToTensor(), # convert a PIL image or ndarray to tensor. \n])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.342451Z","iopub.execute_input":"2023-04-10T07:07:03.342869Z","iopub.status.idle":"2023-04-10T07:07:03.353727Z","shell.execute_reply.started":"2023-04-10T07:07:03.342833Z","shell.execute_reply":"2023-04-10T07:07:03.352549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomImageDataset(root_dir, df_train, transform=transform, target_transform=target_transform)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.356008Z","iopub.execute_input":"2023-04-10T07:07:03.356867Z","iopub.status.idle":"2023-04-10T07:07:03.365585Z","shell.execute_reply.started":"2023-04-10T07:07:03.356828Z","shell.execute_reply":"2023-04-10T07:07:03.364576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset = CustomImageDataset(root_dir, df_val, transform=val_transform, target_transform=target_transform)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.367184Z","iopub.execute_input":"2023-04-10T07:07:03.367677Z","iopub.status.idle":"2023-04-10T07:07:03.374291Z","shell.execute_reply.started":"2023-04-10T07:07:03.367632Z","shell.execute_reply":"2023-04-10T07:07:03.373000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=10, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.375894Z","iopub.execute_input":"2023-04-10T07:07:03.376696Z","iopub.status.idle":"2023-04-10T07:07:03.382944Z","shell.execute_reply.started":"2023-04-10T07:07:03.376661Z","shell.execute_reply":"2023-04-10T07:07:03.381270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def vis(img, label):\n #   fig, axs = plt.subplots(1, 4, figsize=(15, 15))\n  #  axs[0].imshow(img[0])\n   # axs[1].imshow(img[1])\n    #axs[2].imshow(transforms.ToPILImage()(img * 255), interpolation=\"bicubic\")\n    #axs[3].imshow(label)\n\n#for v, (i, j) in enumerate(train_loader):\n    #print('batch: ', v)\n    #print(i.size(), torch.max(i), torch.min(i))\n    #print(j.size(), torch.max(j), torch.min(j))\n    #vis(i[0].squeeze(), j[0][0])\n    #plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.384582Z","iopub.execute_input":"2023-04-10T07:07:03.386764Z","iopub.status.idle":"2023-04-10T07:07:03.393752Z","shell.execute_reply.started":"2023-04-10T07:07:03.386732Z","shell.execute_reply":"2023-04-10T07:07:03.392739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\noptimizer = optim.Adam(network.parameters(), lr = 0.000001)\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.395315Z","iopub.execute_input":"2023-04-10T07:07:03.395915Z","iopub.status.idle":"2023-04-10T07:07:03.404067Z","shell.execute_reply.started":"2023-04-10T07:07:03.395876Z","shell.execute_reply":"2023-04-10T07:07:03.403010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_valid_loss = np.inf\nfor epoch in range(18, 30):\n    total_loss = 0\n    #total_correct = 0\n    pbar = tqdm(train_loader)\n    for batch in pbar:\n        if torch.cuda.is_available():\n            images,labels = batch\n            images, labels = images.cuda(), labels.cuda()\n        preds = network(images.float().cuda())\n        t1 = nn.HuberLoss().cuda()\n        #t1 = nn.BCEWithLogitsLoss().cuda()\n        loss = t1(preds, labels.float().cuda())\n        pbar.set_description(f'Loss -> {loss}')\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.to('cpu').item()\n        #total_correct += get_num_correct(preds, labels)\n        \n    \n    valid_loss = 0.0\n    network.eval()     # Optional when not using Model Specific layer\n    vbar = tqdm(validation_loader)\n    with torch.no_grad():\n        for vbatch in vbar:\n            if torch.cuda.is_available():\n                data, labels = vbatch\n                data, labels = data.cuda(), labels.cuda()\n\n            target = network(data.float()).cuda()\n            t1 = nn.HuberLoss().cuda()\n            loss = t1(target,labels).cuda()\n            valid_loss += loss.to('cpu').item() \n            pbar.set_description(f'Validation Loss -> {loss}')\n            \n    print(f'Epoch {epoch+1} \\t\\t Training Loss: {total_loss} \\t\\t Validation Loss: {valid_loss/len(validation_loader)}')\n    torch.save(network, f\"model_4({epoch+1})_{valid_loss/len(validation_loader)}.pth\")\n        \n    print(f'Epoch ==>> {epoch+1}  \\t\\t Loss ==>> {total_loss/len(train_loader)}')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:07:03.406356Z","iopub.execute_input":"2023-04-10T07:07:03.406625Z"},"trusted":true},"execution_count":null,"outputs":[]}]}